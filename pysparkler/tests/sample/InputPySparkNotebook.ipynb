{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e40a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "from pandas import DataFrame as df\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.ml.param.shared import *\n",
    "\n",
    "spark = SparkSession.builder.appName('example').getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "data = [(\"James\", \"\", \"Smith\", \"36636\", \"M\", 60000),\n",
    "        (\"Jen\", \"Mary\", \"Brown\", \"\", \"F\", 0)]\n",
    "\n",
    "columns = [\"first_name\", \"middle_name\", \"last_name\", \"dob\", \"gender\", \"salary\"]\n",
    "pysparkDF = spark.createDataFrame(data=data, schema=columns, verifySchema=True)\n",
    "\n",
    "pandasDF = pysparkDF.toPandas()\n",
    "print(pandasDF)\n",
    "\n",
    "data = [Row(name=\"James,,Smith\", lang=[\"Java\", \"Scala\", \"C++\"], state=\"CA\"),\n",
    "        Row(name=\"Robert,,Williams\", lang=[\"CSharp\", \"VB\"], state=\"NV\")]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "print(rdd.collect())\n",
    "\n",
    "ps_df = ps.DataFrame(np.arange(12).reshape(3, 4), columns=['A', 'B', 'C', 'D'])\n",
    "ps_df.drop(['B', 'C'])\n",
    "\n",
    "a_column_values = list(ps_df['A'].unique())\n",
    "repr_a_column_values = [repr(value) for value in a_column_values]\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"America/Los_Angeles\")\n",
    "tz_df = spark.createDataFrame([28801], \"long\").selectExpr(\"timestamp(value) as ts\")\n",
    "tz_df.show()\n",
    "\n",
    "rp_df = spark.createDataFrame([\n",
    "        (10, 80.5, \"Alice\", None),\n",
    "        (5, None, \"Bob\", None),\n",
    "        (None, None, \"Tom\", None),\n",
    "        (None, None, None, True)],\n",
    "        schema=[\"age\", \"height\", \"name\", \"bool\"])\n",
    "\n",
    "rp_df.na.replace('Alice').show()\n",
    "rp_df.na.fill(False).show()\n",
    "rp_df.fillna(True).show()\n",
    "\n",
    "\n",
    "def truncate(truncate=True):\n",
    "        try:\n",
    "                int_truncate = int(truncate)\n",
    "        except ValueError as ex:\n",
    "                raise TypeError(\n",
    "                        \"Parameter 'truncate={}' should be either bool or int.\".format(truncate)\n",
    "                )\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Spark 2.4.4 - Python 3 (venv)",
   "language": "python",
   "name": "spark24-python3-venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
